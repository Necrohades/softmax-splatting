{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-22T09:23:46.213789Z",
     "start_time": "2025-09-22T09:23:43.829732Z"
    }
   },
   "source": [
    "import dataset_triplet\n",
    "import softmax_basic\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torchvision.transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "class AffineFlow(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sin = torch.nn.Parameter(requires_grad=True)\n",
    "        self.cos = torch.nn.Parameter(requires_grad=False)\n",
    "\n",
    "    def forward(self, tenOne: torch.Tensor, tenTwo: torch.Tensor):\n",
    "        intWidth = tenOne.shape[3] and tenTwo.shape[3]\n",
    "        intHeight = tenOne.shape[2] and tenTwo.shape[2]\n",
    "\n",
    "        tenOne = self.netExtractor(tenOne)\n",
    "\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def preprocess(image: torch.Tensor) -> torch.Tensor:\n",
    "    batch_size, height, width, channels = image.shape\n",
    "    assert channels == 3\n",
    "    preprocessed = image.cuda().permute((0, 3, 1, 2))  # .view(batch_size, channels, height, width)\n",
    "    pad = [0, width & 1, 0, height & 1]\n",
    "    if (width | height) & 1:\n",
    "        preprocessed = torch.nn.functional.pad(input=preprocessed, pad=pad, mode=\"replicate\")\n",
    "    return preprocessed\n",
    "\n",
    "\n",
    "def to_image(image: torch.Tensor, index: int = 0) -> PIL.Image.Image:\n",
    "    array = image.clip(0.0, 1.0).permute((0, 2, 3, 1))[index].numpy(force=True) * 255.0\n",
    "    return PIL.Image.fromarray(array.astype(np.uint8))"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T09:25:46.030698Z",
     "start_time": "2025-09-22T09:25:45.568699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputWidth = 448\n",
    "inputHeight = 256\n",
    "input_size = inputWidth * inputHeight * 3\n",
    "batch_size = 1\n",
    "learning_rate = 1e-4\n",
    "\n",
    "train_data = dataset_triplet.Dataset(\"/home/tonifuentes/Pictures/archive/vimeo_triplet/\", split=\"train\")\n",
    "test_data  = dataset_triplet.Dataset(\"/home/tonifuentes/Pictures/archive/vimeo_triplet/\", split=\"test\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "net = softmax_basic.Model()\n",
    "loss_function = torch.nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "netNetwork = softmax_basic.Model().cuda()"
   ],
   "id": "8a78e7e960c3d7ba",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T09:27:05.642282Z",
     "start_time": "2025-09-22T09:27:05.640565Z"
    }
   },
   "cell_type": "code",
   "source": "it = iter(train_loader)",
   "id": "bccb0ff8d7d4a25",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:09:23.500537Z",
     "start_time": "2025-09-22T09:51:09.826425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "verbosity = 1000\n",
    "end = 5000\n",
    "\n",
    "with open(\"losses.txt\", \"a\") as losses_file:\n",
    "    for i, (images, gt) in enumerate(it, 1):\n",
    "        # images = Variable(torch.cat([image.view(batch_size, 3, inputHeight, inputWidth, -1) for image in images], dim=4)).cuda()\n",
    "        images = Variable(torch.cat([image.view(batch_size, 3, inputHeight, inputWidth, -1) for image in map(preprocess, images)], dim=4)).cuda()\n",
    "        # gt = gt.numpy().transpose(0, 3, 1, 2)[:, ::-1, :, :]\n",
    "        # gt = torch.from_numpy(gt.copy()).cuda()\n",
    "        gt = preprocess(gt)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = netNetwork(images)\n",
    "        # output = output.view(*output.shape[1:])\n",
    "\n",
    "        loss = loss_function(output, gt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        verbosity = 1000\n",
    "        if not i % verbosity:\n",
    "            print(f\"step: {i}, loss: {loss.item()}\", file=losses_file)\n",
    "            print(f\"step: {i}, loss: {loss.item()}\")\n",
    "            # PIL.Image.fromarray((output.clip(0.0, 1.0).numpy(force=True).transpose(1, 2, 0)[:, :, ::-1] * 255.0).astype(np.uint8)).save(f\"film_out{i//100}.png\")\n",
    "            # PIL.Image.fromarray((gt.clip(0.0, 1.0).view(*gt.shape[1:]).numpy(force=True).transpose(1, 2, 0)[:, :, ::-1] * 255.0).astype(np.uint8)).save(f\"film_gt{i//100}.png\")\n",
    "            # PIL.Image.fromarray((gt.clip(0.0, 1.0).view(*gt.shape[1:]).numpy(force=True) * 255.0).astype(np.uint8)).save(f\"film_gt{i//100}.png\")\n",
    "            to_image(output).save(f\"film_out{i//verbosity}.png\")\n",
    "            to_image(gt).save(f\"film_gt{i//verbosity}.png\")\n",
    "        if i > end:\n",
    "            break"
   ],
   "id": "7dfdc247b8cb70c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1000, loss: 0.007285438943654299\n",
      "step: 2000, loss: 0.011145318858325481\n",
      "step: 3000, loss: 0.03419552743434906\n",
      "step: 4000, loss: 0.025576364248991013\n",
      "step: 5000, loss: 0.020469453185796738\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T10:12:49.649796Z",
     "start_time": "2025-09-22T10:12:49.611793Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(netNetwork.state_dict(), \"model.txt\")",
   "id": "8070269bf7156540",
   "outputs": [],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
